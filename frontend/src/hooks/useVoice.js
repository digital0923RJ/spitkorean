// frontend/src/hooks/useVoice.js
import { useCallback, useEffect, useRef, useState } from 'react';
import { useDispatch, useSelector } from 'react-redux';
import toast from 'react-hot-toast';

// Redux ì•¡ì…˜ë“¤
import { setRecording, setMuted } from '@store/slices/talkSlice';
import { analyzePronunciation } from '@store/slices/feedbackSlice';

// ì‚¬ìš©ì ì •ë³´
import { selectUser } from '@store/slices/authSlice';

/**
 * ìŒì„± ì²˜ë¦¬ í†µí•© í›…
 * WebRTC ë…¹ìŒ, Whisper ì¸ì‹, TTS ì¬ìƒ, ë°œìŒ ë¶„ì„ì„ í†µí•© ê´€ë¦¬
 * Talk Like You Mean It, Korean Journey ë“±ì—ì„œ ê³µìš© ì‚¬ìš©
 */
const useVoice = () => {
  const dispatch = useDispatch();
  const user = useSelector(selectUser);

  // ë¡œì»¬ ìƒíƒœ
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isPlayingTTS, setIsPlayingTTS] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [supportedFormats, setSupportedFormats] = useState([]);
  const [isSupported, setIsSupported] = useState(true);
  const [errorMessage, setErrorMessage] = useState(null);

  // ì„¤ì •
  const [voiceSettings, setVoiceSettings] = useState({
    sampleRate: 44100,
    channelCount: 1,
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true,
    ttsVoiceGender: 'female', // female, male
    ttsSpeed: 1.0, // 0.5 ~ 2.0
    ttsPitch: 0.0, // -20.0 ~ 20.0
    autoPlayTTS: false,
    recordingFormat: 'webm', // webm, mp4, wav
    maxRecordingTime: 60000, // 60ì´ˆ
    minRecordingTime: 1000, // 1ì´ˆ
    pronunciationThreshold: 70 // ë°œìŒ ì ìˆ˜ ì„ê³„ê°’
  });

  // Refs
  const mediaRecorderRef = useRef(null);
  const audioStreamRef = useRef(null);
  const audioChunksRef = useRef([]);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const ttsAudioRef = useRef(null);
  const recordingTimerRef = useRef(null);
  const levelCheckIntervalRef = useRef(null);

  // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
  const checkBrowserSupport = useCallback(() => {
    const supported = {
      mediaRecorder: typeof MediaRecorder !== 'undefined',
      getUserMedia: navigator.mediaDevices && navigator.mediaDevices.getUserMedia,
      audioContext: typeof (window.AudioContext || window.webkitAudioContext) !== 'undefined',
      speechSynthesis: 'speechSynthesis' in window
    };

    const isFullySupported = Object.values(supported).every(Boolean);
    setIsSupported(isFullySupported);

    if (!isFullySupported) {
      const missing = Object.entries(supported)
        .filter(([_, isSupported]) => !isSupported)
        .map(([feature]) => feature);
      
      setErrorMessage(`ë¸Œë¼ìš°ì €ê°€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${missing.join(', ')}`);
    }

    // ì§€ì›ë˜ëŠ” MIME íƒ€ì… í™•ì¸
    const formats = ['webm', 'mp4', 'wav'].filter(format => {
      const mimeTypes = {
        webm: ['audio/webm', 'audio/webm;codecs=opus'],
        mp4: ['audio/mp4', 'audio/mp4;codecs=mp4a.40.2'],
        wav: ['audio/wav', 'audio/wave']
      };
      
      return mimeTypes[format].some(mimeType => 
        MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(mimeType)
      );
    });

    setSupportedFormats(formats);
    
    return isFullySupported;
  }, []);

  // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
  const requestMicrophonePermission = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: voiceSettings.sampleRate,
          channelCount: voiceSettings.channelCount,
          echoCancellation: voiceSettings.echoCancellation,
          noiseSuppression: voiceSettings.noiseSuppression,
          autoGainControl: voiceSettings.autoGainControl
        }
      });

      // ê¶Œí•œ íšë“ í›„ ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¼ í•´ì œ
      stream.getTracks().forEach(track => track.stop());
      
      toast.success('ë§ˆì´í¬ ê¶Œí•œì´ í—ˆìš©ë˜ì—ˆìŠµë‹ˆë‹¤.');
      return true;
    } catch (error) {
      console.error('ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨:', error);
      
      let errorMsg = 'ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
      if (error.name === 'NotFoundError') {
        errorMsg = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      } else if (error.name === 'NotAllowedError') {
        errorMsg = 'ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.';
      } else if (error.name === 'NotReadableError') {
        errorMsg = 'ë§ˆì´í¬ê°€ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.';
      }
      
      setErrorMessage(errorMsg);
      toast.error(errorMsg);
      return false;
    }
  }, [voiceSettings]);

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘
  const startAudioLevelMonitoring = useCallback((stream) => {
    try {
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      audioContextRef.current = new AudioContext();
      
      const source = audioContextRef.current.createMediaStreamSource(stream);
      analyserRef.current = audioContextRef.current.createAnalyser();
      
      analyserRef.current.fftSize = 256;
      source.connect(analyserRef.current);
      
      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
      
      const checkLevel = () => {
        if (analyserRef.current && isRecording) {
          analyserRef.current.getByteFrequencyData(dataArray);
          
          // í‰ê·  ë³¼ë¥¨ ê³„ì‚°
          const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
          const normalizedLevel = Math.min(average / 128, 1);
          
          setAudioLevel(normalizedLevel);
          
          levelCheckIntervalRef.current = requestAnimationFrame(checkLevel);
        }
      };
      
      checkLevel();
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨:', error);
    }
  }, [isRecording]);

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
  const stopAudioLevelMonitoring = useCallback(() => {
    if (levelCheckIntervalRef.current) {
      cancelAnimationFrame(levelCheckIntervalRef.current);
      levelCheckIntervalRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    
    setAudioLevel(0);
  }, []);

  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    if (!isSupported) {
      toast.error('ë¸Œë¼ìš°ì €ì—ì„œ ìŒì„± ë…¹ìŒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return false;
    }

    if (isRecording) {
      toast.warn('ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤.');
      return false;
    }

    try {
      setErrorMessage(null);
      setIsRecording(true);
      dispatch(setRecording(true));

      // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: voiceSettings.sampleRate,
          channelCount: voiceSettings.channelCount,
          echoCancellation: voiceSettings.echoCancellation,
          noiseSuppression: voiceSettings.noiseSuppression,
          autoGainControl: voiceSettings.autoGainControl
        }
      });

      audioStreamRef.current = stream;
      audioChunksRef.current = [];

      // MIME íƒ€ì… ê²°ì •
      const format = voiceSettings.recordingFormat;
      const mimeTypes = {
        webm: ['audio/webm;codecs=opus', 'audio/webm'],
        mp4: ['audio/mp4;codecs=mp4a.40.2', 'audio/mp4'],
        wav: ['audio/wav', 'audio/wave']
      };

      let selectedMimeType = null;
      for (const mimeType of mimeTypes[format] || []) {
        if (MediaRecorder.isTypeSupported(mimeType)) {
          selectedMimeType = mimeType;
          break;
        }
      }

      if (!selectedMimeType) {
        throw new Error(`${format} í˜•ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.`);
      }

      // MediaRecorder ì„¤ì •
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: selectedMimeType,
        audioBitsPerSecond: 128000
      });

      // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        setIsRecording(false);
        dispatch(setRecording(false));
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        if (audioStreamRef.current) {
          audioStreamRef.current.getTracks().forEach(track => track.stop());
          audioStreamRef.current = null;
        }
        
        stopAudioLevelMonitoring();
        
        if (recordingTimerRef.current) {
          clearInterval(recordingTimerRef.current);
          recordingTimerRef.current = null;
        }
        
        setRecordingDuration(0);
      };

      mediaRecorderRef.current.onerror = (event) => {
        console.error('MediaRecorder ì˜¤ë¥˜:', event.error);
        toast.error('ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        stopRecording();
      };

      // ë…¹ìŒ ì‹œì‘
      mediaRecorderRef.current.start(100); // 100msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘

      // ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘
      startAudioLevelMonitoring(stream);

      // ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸
      const startTime = Date.now();
      recordingTimerRef.current = setInterval(() => {
        const duration = Date.now() - startTime;
        setRecordingDuration(duration);
        
        // ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì²´í¬
        if (duration >= voiceSettings.maxRecordingTime) {
          stopRecording();
          toast.warn(`ìµœëŒ€ ë…¹ìŒ ì‹œê°„(${voiceSettings.maxRecordingTime / 1000}ì´ˆ)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.`);
        }
      }, 100);

      toast.success('ë…¹ìŒì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
      return true;
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      setIsRecording(false);
      dispatch(setRecording(false));
      
      let errorMsg = 'ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      if (error.name === 'NotAllowedError') {
        errorMsg = 'ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
      } else if (error.name === 'NotFoundError') {
        errorMsg = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      }
      
      setErrorMessage(errorMsg);
      toast.error(errorMsg);
      return false;
    }
  }, [isSupported, isRecording, voiceSettings, dispatch, startAudioLevelMonitoring, stopAudioLevelMonitoring]);

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(async () => {
    if (!isRecording || !mediaRecorderRef.current) {
      return null;
    }

    return new Promise((resolve, reject) => {
      const originalOnStop = mediaRecorderRef.current.onstop;
      
      mediaRecorderRef.current.onstop = async (event) => {
        // ì›ë˜ onstop í•¸ë“¤ëŸ¬ ì‹¤í–‰
        if (originalOnStop) {
          originalOnStop(event);
        }

        try {
          // ë…¹ìŒ ì‹œê°„ ì²´í¬
          if (recordingDuration < voiceSettings.minRecordingTime) {
            toast.warn(`ìµœì†Œ ${voiceSettings.minRecordingTime / 1000}ì´ˆ ì´ìƒ ë…¹ìŒí•´ì£¼ì„¸ìš”.`);
            resolve(null);
            return;
          }

          // ì˜¤ë””ì˜¤ Blob ìƒì„±
          const audioBlob = new Blob(audioChunksRef.current, {
            type: mediaRecorderRef.current.mimeType
          });

          if (audioBlob.size === 0) {
            throw new Error('ë…¹ìŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
          }

          toast.success(`ë…¹ìŒ ì™„ë£Œ (${Math.round(recordingDuration / 1000)}ì´ˆ)`);
          resolve(audioBlob);
        } catch (error) {
          console.error('ë…¹ìŒ ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
          toast.error('ë…¹ìŒ ì™„ë£Œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
          reject(error);
        }
      };

      mediaRecorderRef.current.stop();
    });
  }, [isRecording, recordingDuration, voiceSettings.minRecordingTime]);

  // TTS ìŒì„± ì¬ìƒ
  const playTTS = useCallback(async (text, options = {}) => {
    if (!text || !text.trim()) {
      toast.error('ì¬ìƒí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.');
      return false;
    }

    if (isPlayingTTS) {
      toast.warn('ì´ë¯¸ ìŒì„±ì´ ì¬ìƒ ì¤‘ì…ë‹ˆë‹¤.');
      return false;
    }

    try {
      setIsPlayingTTS(true);

      // ë°±ì—”ë“œ TTS API í˜¸ì¶œ (tts_service.pyì™€ ì—°ë™)
      const response = await fetch('/api/v1/common/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${localStorage.getItem('auth_token')}`
        },
        body: JSON.stringify({
          text: text.trim(),
          voice_gender: options.voiceGender || voiceSettings.ttsVoiceGender,
          speed: options.speed || voiceSettings.ttsSpeed,
          pitch: options.pitch || voiceSettings.ttsPitch,
          language: 'ko-KR'
        })
      });

      if (!response.ok) {
        throw new Error(`TTS API ì˜¤ë¥˜: ${response.status}`);
      }

      const audioArrayBuffer = await response.arrayBuffer();
      const audioBlob = new Blob([audioArrayBuffer], { type: 'audio/mp3' });
      const audioUrl = URL.createObjectURL(audioBlob);

      // ì˜¤ë””ì˜¤ ì¬ìƒ
      if (ttsAudioRef.current) {
        ttsAudioRef.current.pause();
        URL.revokeObjectURL(ttsAudioRef.current.src);
      }

      ttsAudioRef.current = new Audio(audioUrl);
      
      ttsAudioRef.current.onended = () => {
        setIsPlayingTTS(false);
        URL.revokeObjectURL(audioUrl);
      };

      ttsAudioRef.current.onerror = (error) => {
        console.error('TTS ì¬ìƒ ì˜¤ë¥˜:', error);
        setIsPlayingTTS(false);
        URL.revokeObjectURL(audioUrl);
        toast.error('ìŒì„± ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      };

      await ttsAudioRef.current.play();
      return true;
    } catch (error) {
      console.error('TTS ì¬ìƒ ì‹¤íŒ¨:', error);
      setIsPlayingTTS(false);
      toast.error('ìŒì„± ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      return false;
    }
  }, [isPlayingTTS, voiceSettings]);

  // TTS ì¬ìƒ ì¤‘ì§€
  const stopTTS = useCallback(() => {
    if (ttsAudioRef.current) {
      ttsAudioRef.current.pause();
      ttsAudioRef.current.currentTime = 0;
      setIsPlayingTTS(false);
    }
  }, []);

  // ë°œìŒ ë¶„ì„ (Korean Journey, Talkì—ì„œ ì‚¬ìš©)
  const analyzePronunciationAudio = useCallback(async (audioBlob, originalText, level = 'beginner') => {
    if (!audioBlob || !originalText) {
      toast.error('ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
      return null;
    }

    try {
      setIsProcessing(true);

      // ë°±ì—”ë“œ ë°œìŒ ë¶„ì„ API í˜¸ì¶œ (whisper_service.pyì™€ ì—°ë™)
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      formData.append('original_text', originalText);
      formData.append('level', level);

      const response = await fetch('/api/v1/journey/pronunciation-analysis', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${localStorage.getItem('auth_token')}`
        },
        body: formData
      });

      if (!response.ok) {
        throw new Error(`ë°œìŒ ë¶„ì„ API ì˜¤ë¥˜: ${response.status}`);
      }

      const result = await response.json();

      if (result.status === 'success') {
        const analysisData = result.data;

        // Reduxì— ë°œìŒ ë¶„ì„ ê²°ê³¼ ì €ì¥
        await dispatch(analyzePronunciation({
          originalText,
          transcribedText: analysisData.transcribed_text,
          pronunciationScore: analysisData.pronunciation_score,
          level,
          nativeLanguage: user?.profile?.nativeLanguage || 'en'
        })).unwrap();

        // ë°œìŒ ì ìˆ˜ì— ë”°ë¥¸ í”¼ë“œë°±
        if (analysisData.pronunciation_score >= voiceSettings.pronunciationThreshold) {
          toast.success(`í›Œë¥­í•œ ë°œìŒì…ë‹ˆë‹¤! (${analysisData.pronunciation_score}ì )`);
        } else {
          toast(`ë°œìŒì„ ê°œì„ í•´ë³´ì„¸ìš”. (${analysisData.pronunciation_score}ì )`, {
            icon: 'ğŸ’ª',
            duration: 3000
          });
        }

        return {
          score: analysisData.pronunciation_score,
          transcribedText: analysisData.transcribed_text,
          analysis: analysisData.detailed_analysis,
          improvements: analysisData.improvement_suggestions
        };
      } else {
        throw new Error(result.message || 'ë°œìŒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    } catch (error) {
      console.error('ë°œìŒ ë¶„ì„ ì‹¤íŒ¨:', error);
      toast.error('ë°œìŒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      return null;
    } finally {
      setIsProcessing(false);
    }
  }, [dispatch, user, voiceSettings.pronunciationThreshold]);

  // ìŒì„± ì„¤ì • ì—…ë°ì´íŠ¸
  const updateVoiceSettings = useCallback((newSettings) => {
    setVoiceSettings(prev => ({ ...prev, ...newSettings }));
    
    if (newSettings.ttsVoiceGender) {
      toast.success(`ìŒì„± ì„±ë³„ì´ ${newSettings.ttsVoiceGender === 'female' ? 'ì—¬ì„±' : 'ë‚¨ì„±'}ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.`);
    }
  }, []);

  // ìŒì„± ì„¤ì • ì´ˆê¸°í™”
  const resetVoiceSettings = useCallback(() => {
    setVoiceSettings({
      sampleRate: 44100,
      channelCount: 1,
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
      ttsVoiceGender: 'female',
      ttsSpeed: 1.0,
      ttsPitch: 0.0,
      autoPlayTTS: false,
      recordingFormat: 'webm',
      maxRecordingTime: 60000,
      minRecordingTime: 1000,
      pronunciationThreshold: 70
    });
    
    toast.success('ìŒì„± ì„¤ì •ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
  }, []);

  // ë§ˆì´í¬ í…ŒìŠ¤íŠ¸
  const testMicrophone = useCallback(async () => {
    try {
      toast.loading('ë§ˆì´í¬ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì¤‘...');
      
      const success = await startRecording();
      if (success) {
        // 3ì´ˆ í›„ ìë™ ì¤‘ì§€
        setTimeout(async () => {
          const audioBlob = await stopRecording();
          if (audioBlob) {
            toast.success('ë§ˆì´í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!');
          }
        }, 3000);
      }
    } catch (error) {
      console.error('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error);
      toast.error('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  }, [startRecording, stopRecording]);

  // ì´ˆê¸°í™” ë° ì •ë¦¬
  useEffect(() => {
    checkBrowserSupport();

    return () => {
      // ì •ë¦¬ ì‘ì—…
      if (mediaRecorderRef.current && isRecording) {
        mediaRecorderRef.current.stop();
      }
      
      if (audioStreamRef.current) {
        audioStreamRef.current.getTracks().forEach(track => track.stop());
      }
      
      if (ttsAudioRef.current) {
        ttsAudioRef.current.pause();
        if (ttsAudioRef.current.src) {
          URL.revokeObjectURL(ttsAudioRef.current.src);
        }
      }
      
      stopAudioLevelMonitoring();
      
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
      }
      
      setIsRecording(false);
      dispatch(setRecording(false));
    };
  }, [checkBrowserSupport, isRecording, dispatch, stopAudioLevelMonitoring]);

  return {
    // ìƒíƒœ
    isRecording,
    isProcessing,
    isPlayingTTS,
    audioLevel,
    recordingDuration,
    supportedFormats,
    isSupported,
    errorMessage,
    voiceSettings,
    
    // ë…¹ìŒ ê´€ë ¨
    startRecording,
    stopRecording,
    requestMicrophonePermission,
    testMicrophone,
    
    // TTS ê´€ë ¨
    playTTS,
    stopTTS,
    
    // ë°œìŒ ë¶„ì„
    analyzePronunciationAudio,
    
    // ì„¤ì • ê´€ë¦¬
    updateVoiceSettings,
    resetVoiceSettings,
    
    // ìœ í‹¸ë¦¬í‹°
    checkBrowserSupport,
    
    // ê³„ì‚°ëœ ê°’ë“¤
    recordingProgress: Math.min((recordingDuration / voiceSettings.maxRecordingTime) * 100, 100),
    formattedDuration: `${Math.floor(recordingDuration / 1000)}:${String(Math.floor((recordingDuration % 1000) / 10)).padStart(2, '0')}`,
    canRecord: isSupported && !isRecording && !isProcessing,
    canPlayTTS: isSupported && !isPlayingTTS,
    audioLevelPercent: Math.round(audioLevel * 100)
  };
};

export default useVoice;